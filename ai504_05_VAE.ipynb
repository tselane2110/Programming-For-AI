{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFoq-khqMAh7"
   },
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXpqf4nGMAh8"
   },
   "source": [
    "## 1. Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuiAb_LX2QiB"
   },
   "source": [
    "### 1) Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOFx3VQpMAh-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBDG968zMAiC"
   },
   "source": [
    "### 2) Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oxPTgvcjMAiD"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uaV_HtJMAiG"
   },
   "source": [
    "## 2. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeRww6jr2iZd"
   },
   "source": [
    "### 1) Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "he-GrlguMAiG",
    "outputId": "4197207d-1d8f-4bc4-fbb3-834733675138"
   },
   "outputs": [],
   "source": [
    "mnist_train = dset.MNIST(\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "mnist_test = dset.MNIST(\"./\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "mnist_train, mnist_val = torch.utils.data.random_split(mnist_train, [50000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2flOQIh3Mu_",
    "outputId": "c42dbd20-3d32-4790-a61d-fcdf30fb739e"
   },
   "outputs": [],
   "source": [
    "mnist_train[0][0].size()    # (1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VFezXtf51OH_",
    "outputId": "e96f02eb-dc0c-4b0f-e0e7-74c91189ed95"
   },
   "outputs": [],
   "source": [
    "mnist_train[0][1]           # label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKz97cYDMAiJ"
   },
   "source": [
    "### 2) Set DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2YVorheoJKR"
   },
   "outputs": [],
   "source": [
    "dataloaders = {}\n",
    "dataloaders['train'] = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "dataloaders['val'] = DataLoader(mnist_val, batch_size=batch_size, shuffle=False)\n",
    "dataloaders['test'] = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V83NRcPjaE1t",
    "outputId": "2566e619-b1b7-490c-9d92-0fa1c04b2360"
   },
   "outputs": [],
   "source": [
    "len(dataloaders[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWlU96lLMAiM"
   },
   "source": [
    "## 3. Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 710
    },
    "id": "PRHH_dJX9RMM",
    "outputId": "67d93b95-6269-4fca-f998-3c7c9471dbf9"
   },
   "outputs": [],
   "source": [
    "# https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html\n",
    "!wget -q https://www.dropbox.com/s/lmpjzzkqhk7d408/vae_gaussian.png\n",
    "Image(\"vae_gaussian.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZjl2GHl5gj8"
   },
   "source": [
    "### 1) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTd6rSIFMAiN"
   },
   "outputs": [],
   "source": [
    "# build your own variational autoencoder\n",
    "# encoder: 784(28*28) -> 256\n",
    "# sampling: 256 -> 10\n",
    "# decoder: 10 -> 256 -> 784(28*28)\n",
    "\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VariationalAutoencoder,self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, ??),    \n",
    "            nn.Tanh(),                          # activation function\n",
    "        )\n",
    "        \n",
    "        self.fc_mu = nn.Linear(??, ??)\n",
    "        self.fc_var = nn.Linear(??, ??)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(??, ??),\n",
    "            nn.Tanh(),                          # activation function\n",
    "            nn.Linear(??, 28*28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "                \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        log_var = self.fc_var(h)\n",
    "        return mu, log_var\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = ??\n",
    "        eps = ??\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        recon = self.decoder(z)\n",
    "        return recon\n",
    "    \n",
    "                \n",
    "    def forward(self, x):                # x: (batch_size, 1, 28, 28)\n",
    "        batch_size = x.size(0)\n",
    "        mu, log_var = self.encode(x.view(batch_size, -1))\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        out = self.decode(z)\n",
    "        return out, mu, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLiqw-rpMAiP"
   },
   "source": [
    "### 2) Loss func & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZKc1UKNgMAiQ",
    "outputId": "fa7ce832-a9a2-43d5-ccc4-a04b837cce79"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1yg6SHyI9RMO"
   },
   "outputs": [],
   "source": [
    "BCE = torch.nn.BCELoss(reduction='sum')\n",
    "\n",
    "def loss_func(x, recon_x, mu, log_var):\n",
    "    #batch_size = x.size(0)\n",
    "    #MSE_loss = MSE(x, recon_x.view(batch_size, 1, 28, 28))\n",
    "\n",
    "    BCE_loss = BCE(recon_x, x.view(-1, 784))\n",
    "    KLD_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE_loss + KLD_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9o1euqGI0jm"
   },
   "outputs": [],
   "source": [
    "model = VariationalAutoencoder().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_W2UI2F_MAiT"
   },
   "source": [
    "## 4. Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSa4Z2lMcGwL"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=10):\n",
    "    \"\"\"\n",
    "    model: model to train\n",
    "    dataloaders: train, val, test data's loader\n",
    "    criterion: loss function\n",
    "    optimizer: optimizer to update your model\n",
    "    \"\"\"\n",
    "    since = time.time()\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_val_loss = 100000000\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()            # Set model to training mode\n",
    "            else:\n",
    "                model.eval()            # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)                                       # transfer inputs to GPU \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    outputs, mu, log_var = model(inputs)\n",
    "                    loss = criterion(inputs, outputs, mu, log_var)  # calculate a loss\n",
    "\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()                             # perform back-propagation from the loss\n",
    "                        optimizer.step()                             # perform gradient descent with given optimizer\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'train':\n",
    "                train_loss_history.append(epoch_loss)\n",
    "\n",
    "            if phase == 'val':\n",
    "                val_loss_history.append(epoch_loss)\n",
    "\n",
    "            if phase == 'val' and epoch_loss < best_val_loss:\n",
    "                best_val_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Loss: {:4f}'.format(best_val_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTgWxvbai42S",
    "outputId": "173ad994-d3d3-425b-fced-fea928da0cbf"
   },
   "outputs": [],
   "source": [
    "best_model, train_loss_history, val_loss_history = train_model(model, dataloaders, loss_func, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CSxdlpwLVjIG"
   },
   "outputs": [],
   "source": [
    "# Let's draw a learning curve like below.\n",
    "plt.plot(train_loss_history, label='train')\n",
    "plt.plot(val_loss_history, label='val')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbYYgt8WTZzY"
   },
   "source": [
    "## 5. Check with Test Image (Can VAE reconstruct input images?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XCKx34u5MAic"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in dataloaders[\"test\"]:\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        outputs, mu, log_var = best_model(inputs)\n",
    "        test_loss = loss_func(inputs, outputs, mu, log_var)\n",
    "        \n",
    "        running_loss += test_loss.item()\n",
    "\n",
    "    test_loss = running_loss / len(dataloaders[\"test\"].dataset)\n",
    "    print(test_loss)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvww5H9GMAie"
   },
   "outputs": [],
   "source": [
    "out_img = torch.squeeze(outputs.cpu().data)\n",
    "print(out_img.size())\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(torch.squeeze(inputs[i]).cpu().numpy(),cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(out_img[i].numpy().reshape(28, 28),cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eA994jG-X53U"
   },
   "source": [
    "## 6. Visualizing MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_W-7sy8WT54"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IzOQPuxchAJq"
   },
   "outputs": [],
   "source": [
    "train_dataset_array = mnist_train.dataset.data.numpy() / 255\n",
    "train_dataset_array = np.float32(train_dataset_array)\n",
    "labels = mnist_train.dataset.targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wn6eMb799RMQ"
   },
   "outputs": [],
   "source": [
    "subset_indices = []\n",
    "subset_indices_per_class = []\n",
    "\n",
    "for i in range(10):\n",
    "    indices = np.where(labels == i)[0]\n",
    "    subset_size = len(indices) // 6\n",
    "    subset_indices += indices[:subset_size].tolist()\n",
    "    subset_indices_per_class.append(indices[:subset_size].tolist())\n",
    "\n",
    "train_dataset_array = train_dataset_array[subset_indices]\n",
    "labels = labels[subset_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPh9EtHZjCqH"
   },
   "outputs": [],
   "source": [
    "train_dataset_array = torch.tensor(train_dataset_array)\n",
    "inputs = train_dataset_array.to(device)\n",
    "outputs, mu, log_var = best_model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cWVqp0DWUg8"
   },
   "outputs": [],
   "source": [
    "encoded = mu.cpu().detach().numpy()\n",
    "tsne = TSNE()   \n",
    "X_train_2D = tsne.fit_transform(encoded)\n",
    "X_train_2D = (X_train_2D - X_train_2D.min()) / (X_train_2D.max() - X_train_2D.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XM23epMaXyua"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_train_2D[:, 0], X_train_2D[:, 1], c=labels, s=10, cmap=\"tab10\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plqT50pDYEqK"
   },
   "source": [
    "Let's make this diagram a bit prettier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbkgwf3zXzI2"
   },
   "outputs": [],
   "source": [
    "# adapted from https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html\n",
    "plt.figure(figsize=(10, 8))\n",
    "cmap = plt.cm.tab10\n",
    "plt.scatter(X_train_2D[:, 0], X_train_2D[:, 1], c=labels, s=10, cmap=cmap)\n",
    "image_positions = np.array([[1., 1.]])\n",
    "for index, position in enumerate(X_train_2D):\n",
    "    dist = np.sum((position - image_positions) ** 2, axis=1)\n",
    "    if np.min(dist) > 0.02: # if far enough from other images\n",
    "        image_positions = np.r_[image_positions, [position]]\n",
    "        imagebox = mpl.offsetbox.AnnotationBbox(\n",
    "            mpl.offsetbox.OffsetImage(torch.squeeze(inputs).cpu().numpy()[index], cmap=\"binary\"),\n",
    "            position, bboxprops={\"edgecolor\": cmap(labels[index]), \"lw\": 2})\n",
    "        plt.gca().add_artist(imagebox)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4tkOPZE9RMR"
   },
   "source": [
    "## 7. Walk through latent space of MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibDxXDwO9RMR"
   },
   "outputs": [],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nnqgKrDc9RMS"
   },
   "outputs": [],
   "source": [
    "mean_encoded = []\n",
    "for i in range(10):\n",
    "    mean_encoded.append(encoded[np.where(labels == i)[0]].mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KlfGT24T9RMS"
   },
   "outputs": [],
   "source": [
    "selected_class = [1, 7]\n",
    "samples = []\n",
    "with torch.no_grad():\n",
    "    for idx, coef in enumerate(np.linspace(0, 1, 10)):\n",
    "        interpolated = coef * mean_encoded[selected_class[0]] + (1.-coef) * mean_encoded[selected_class[1]]\n",
    "        samples.append(interpolated)\n",
    "    samples = np.stack(samples)\n",
    "    z = torch.tensor(samples).to(device)\n",
    "    generated = best_model.decoder(z).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eA6Zmqmw9RMS"
   },
   "outputs": [],
   "source": [
    "generated = generated.view(10, 1, 28, 28)\n",
    "img = make_grid(generated, nrow=10)\n",
    "npimg = img.cpu().numpy()\n",
    "plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "arExnodB9RMS"
   },
   "outputs": [],
   "source": [
    "selected_class = [1, 8]\n",
    "samples = []\n",
    "with torch.no_grad():\n",
    "    for idx, coef in enumerate(np.linspace(0, 1, 10)):\n",
    "        interpolated = coef * mean_encoded[selected_class[0]] + (1.-coef) * mean_encoded[selected_class[1]]\n",
    "        samples.append(interpolated)\n",
    "    samples = np.stack(samples)\n",
    "    z = torch.tensor(samples).to(device)\n",
    "    generated = best_model.decoder(z).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAtKAA3k9RMS"
   },
   "outputs": [],
   "source": [
    "generated = generated.view(10, 1, 28, 28)\n",
    "img = make_grid(generated, nrow=10)\n",
    "npimg = img.cpu().numpy()\n",
    "plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_4EOYUq9RMS"
   },
   "source": [
    "## 8. Comparison between low capacity model and high capacity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kIDBbIc9RMS"
   },
   "outputs": [],
   "source": [
    "# build your own variational autoencoder\n",
    "# encoder: 784(28*28) -> 512 -> 256\n",
    "# sampling: 256 -> 10\n",
    "# decoder: 10 -> 256 -> 512 -> 784(28*28)\n",
    "\n",
    "class VariationalAutoencoderHigh(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VariationalAutoencoderHigh,self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, ??),    \n",
    "            nn.ReLU(),                          # activation function\n",
    "            nn.Linear(??, ??),\n",
    "            nn.ReLU()                           # activation function\n",
    "        )\n",
    "        \n",
    "        self.fc_mu = nn.Linear(??, ??)\n",
    "        self.fc_var = nn.Linear(??, ??)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(??, ??),\n",
    "            nn.ReLU(),                          # activation function\n",
    "            nn.Linear(??, ??),\n",
    "            nn.ReLU(),                          # activation function\n",
    "            nn.Linear(??, 28*28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "                \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        log_var = self.fc_var(h)\n",
    "        return mu, log_var\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = ??\n",
    "        eps = ??\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        recon = self.decoder(z)\n",
    "        return recon\n",
    "    \n",
    "                \n",
    "    def forward(self, x):                # x: (batch_size, 1, 28, 28)\n",
    "        batch_size = x.size(0)\n",
    "        mu, log_var = self.encode(x.view(batch_size, -1))\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        out = self.decode(z)\n",
    "        return out, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NMe-ADbB9RMT"
   },
   "outputs": [],
   "source": [
    "model = VariationalAutoencoderHigh().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9if1c1Mb9RMT"
   },
   "outputs": [],
   "source": [
    "best_model_high, train_loss_history_high, val_loss_history_high = train_model(model, dataloaders, loss_func, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "azj31_51AOmh"
   },
   "outputs": [],
   "source": [
    "# Let's draw a learning curve for low and high capacity models.\n",
    "plt.plot(train_loss_history, label='low_train')\n",
    "plt.plot(val_loss_history, label='low_val')\n",
    "plt.plot(train_loss_history_high, label='high_train')\n",
    "plt.plot(val_loss_history_high, label='high_val')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GymyBSbo-_iQ"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in dataloaders[\"test\"]:\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        outputs, mu, log_var = best_model_high(inputs) # best_model_high \n",
    "        test_loss = loss_func(inputs, outputs, mu, log_var)\n",
    "        \n",
    "        running_loss += test_loss.item()\n",
    "\n",
    "    test_loss = running_loss / len(dataloaders[\"test\"].dataset)\n",
    "    print(test_loss)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJ9tQr4V_wk2"
   },
   "outputs": [],
   "source": [
    "out_img_high = torch.squeeze(outputs.cpu().data) # out_img_high\n",
    "print(out_img.size())\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(torch.squeeze(inputs[i]).cpu().numpy(),cmap='gray')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(out_img[i].numpy().reshape(28, 28),cmap='gray')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(out_img_high[i].numpy().reshape(28, 28),cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. What if we sample z from a normal distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(100, 10).cuda()\n",
    "outputs = best_model_high.decoder(z)\n",
    "out_img_high = torch.squeeze(outputs.cpu().data)\n",
    "print(out_img_high.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(100):\n",
    "    plt.subplot(10, 10, i+1)\n",
    "    plt.imshow(out_img_high[i].reshape(28, 28).numpy(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dE9QYG7aHYO6"
   },
   "source": [
    "## 10. BCE loss and MSE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "zxcZwfXgHYsj",
    "outputId": "69b40ae7-3413-427d-f940-663326c2674e"
   },
   "outputs": [],
   "source": [
    "#Tutorial on Variational Autoencoders Carl Doersch\n",
    "!wget -q https://www.dropbox.com/s/5kkhyo7apxkay5z/BCE_loss%20and%20MSE_loss.PNG\n",
    "Image(\"BCE_loss and MSE_loss.PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7iAm3xkIGvP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ai504_05_VAE.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
